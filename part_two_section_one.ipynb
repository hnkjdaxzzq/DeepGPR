{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f49ebc-6c6d-4757-a168-f84971db0311",
   "metadata": {},
   "source": [
    "# 第三部分：PyTorch与深度学习基础\n",
    "本项目是**中南大学智能雷达实验室**为即将进组的同学准备的培训项目，涵盖从Python基础到深度学习在探地雷达领域的应用。项目设计与文档由智能雷达实验室成员精心编写，旨在帮助新成员快速融入实验室研究工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0628ec7-f6e9-49ad-80d2-1e76112c92e5",
   "metadata": {},
   "source": [
    "## Do-1 深度学习理论基础\n",
    " * 神经网络基本原理\n",
    " * 激活函数与非线性\n",
    " * 前向传播与反向传播\n",
    " * 梯度下降算法\n",
    " * 过拟合与正则化\n",
    " * 批量归一化\n",
    " * 卷积神经网络原理\n",
    " * 池化操作与降维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8876b-984f-4d49-84bd-be4014d2ef63",
   "metadata": {},
   "source": [
    "* 简单理解神经网络：写出一个带有未知参数的函数，这个函数可以对指定的目标任务做出预测，而该参数含有的未知参数需要通过数据去找出来。  \n",
    "![](resource/线性模型.png)  \n",
    "* 其中y是准备要预测的东西（输入），x1为输入信息，未知参数w为<span style=\"color:red\">权重</span>，用来控制输入信息对最终输出的影响有多大，未知参数b为<span style=\"color:red\">偏置</span>，该带有未知参数的函数称为<span style=\"color:red\">模型</span>。<span style=\"color:red\">特征</span>用来指代数据中的有用信息，如图像的边缘、纹理、颜色分布、形状等，这些信息有利于模型进行预测。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d5064-e5b0-4cf9-a5e8-63169d387c90",
   "metadata": {},
   "source": [
    "* 损失函数的输入就为未知参数b、w，作用是来代表在固定好某一对b和w时，该模型的输出好还是不好，例如平均绝对误差（Mean Absolute Error，MAE）:  \n",
    "![](resource/MAE.png)  \n",
    "* 还有均方误差（Mean Squared Error，MSE）：  \n",
    "![](resource/MSE.png)    \n",
    "* MAE、MSE用来计算预测值与你希望的输出（<span style=\"color:red\">标签</span>）之间的差距。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437eb89-fca7-4a7e-b60a-1ebdfa217061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设模型输出和真实标签\n",
    "y_predict = torch.tensor([2.5, 0.0, 2.1], requires_grad=True)\n",
    "y_label = torch.tensor([3.0, -0.5, 2.0])\n",
    "\n",
    "# MSE（均方误差）\n",
    "mse_loss = nn.MSELoss()\n",
    "mse = mse_loss(y_predict, y_label)\n",
    "\n",
    "# MAE（平均绝对误差）\n",
    "mae_loss = nn.L1Loss()\n",
    "mae = mae_loss(y_predict, y_label)\n",
    "print(\"MAE:\", mae.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84231335-01bc-4157-9868-22ff2cd1fc68",
   "metadata": {},
   "source": [
    "* 根据不同的b,w参数，损失函数的大小会发生变化，若能找出一对数值b、w，使得最终的损失值最小，这就是训练的目的，参数通过对输入数据的迭代学习进行更新，逐渐趋向于最优解。  \n",
    "* 如何找出这个最优解，也就是学习策略，常用<span style=\"color:red\">梯度下降法</span>，如下图：  \n",
    "<p align=\"center\">\n",
    "  <img src=\"resource/梯度下降.png\" width=\"35%\">\n",
    "</p>\n",
    "\n",
    "* 为简化问题，先解释损失值L和参数w的关系，首先随机选取一个初始点，计算该点损失值L对参数w的偏导数，就能知道w往哪个方向走（增大或减小）使得损失值L下降，并且斜率大的地方步伐就跨大一点，斜率小的地方步伐就跨小一点。  \n",
    "* <span style=\"color:red\">学习率</span>η也会影响步伐大小，是自己设定的，如果学习率设大一点，每次参数更新就会量大，学习可能会比较快，但是容易使损失在学习的过程中震荡，如果学习率设小一点，每次参数更新只会改变一点点参数的数值，但容易陷入<span style=\"color:red\">局部最小值</span>。这种需要自己设定，而不是机器自己找出来的，称之为<span style=\"color:red\">超参数</span>。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455525e-b3d4-42d4-a479-a1faf23ef2a2",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"resource/局部最小值&全局最小值.png\" width=\"35%\">\n",
    "</p>  \n",
    "\n",
    "* 当参数调整到在该点的梯度（偏导）为零时，有两种情况：<span style=\"color:red\">局部最小值</span>、<span style=\"color:red\">全局最小值</span>，参数更新在这两点都会停止，而我们希望找到的时全局最小值，但学习经常会在局部最小值点停止。\n",
    "* 此外，损失函数是自己定义的，这个图中的曲线并不是一个真实的损失，这个损失的曲线可以是任何形状，而且并不仅仅只与一个或两个参数有关。例如这个模型有57个参数：  \n",
    "![](resource/多参数线性模型.png)\n",
    "* 但是这个模型依旧是个简单的线性模型，输入x与输出y之间可能有复杂的关系，我们可以将输入x与y的映射关系（红色曲线）看作是一组s形状的线（蓝色）与一个常数相加之和。  \n",
    "<p align=\"center\">\n",
    "  <img src=\"resource/非线性模型.png\" width=\"35%\">\n",
    "</p>    \n",
    "\n",
    "* 并且我们常用<span style=\"color:red\">Sigmoid函数</span>来逼近这些蓝色曲线（hard Sigmoid）：  \n",
    "![](resource/Sigmoid函数.png)\n",
    "<p align=\"center\">\n",
    "  <img src=\"resource/Sigmoid图像.png\" width=\"35%\">\n",
    "</p>   \n",
    "\n",
    "* 其中c，b，w是常数，我们可以通过改变这些常数，制造出不同的Sigmoid函数，把不同的Sigmoid函数叠加来逼近各种不同的分段函数，就可以变成任何连续的曲线。\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/不同参数下的Sigmoid函数.png\" width=\"35%\">\n",
    "</p>   \n",
    "\n",
    "* 所以在各种书上对<span style=\"color:red\">激活函数</span>的描述为：激活函数（非线性函数）可以给神经网络增加“非线性能力”，让模型可以学习复杂的模式和关系。常见的激活函数还有<span style=\"color:red\">ReLU</span>。在模型的各个环节增加激活函数，可以使得模型更加灵活：\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/激活函数给模型增加灵活性.png\" width=\"35%\">\n",
    "</p>   \n",
    "\n",
    "* 在实际输入大量数据来寻找最优参数点时，通常会把这大量数据分成一个一个的<span style=\"color:red\">批量（batch）</span>,本来是要把所有的数据拿出来算出一个损失，现在是只拿一个批量里边的数据来算出一个损失，算出梯度，来更新参数，然后继续下一个批量里边的数据算出损失、算出梯度、更新参数，当把所有数据都看过一次，称之为一个<span style=\"color:red\">回合（epoch）</span>，每更新一次参数叫做一次更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de452595-c086-4de6-b0d2-148001c2830d",
   "metadata": {},
   "source": [
    "* <span style=\"color:red\">神经网络</span>由很多个神经元组成，<span style=\"color:red\">神经元</span>通过多个输入与对应的权重相乘，加上一个偏置，然后通过一个激活函数，输出一个结果。神经元很多的模型，那些既不是模型直接接受输入的地方也不是直接输出预测结果的地方，称之为<span style=\"color:red\">隐藏层</span>，人们把神经网络越叠越多越叠越深，例如残差网络（Residual Network,ResNet）可以有152层。\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/神经网络.png\" width=\"35%\">\n",
    "</p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932aadba-54f5-41b7-b897-23c92cefb53b",
   "metadata": {},
   "source": [
    "* 深度学习网络可以看作是一个很深层的神经网络，<span style=\"color:red\">反向传播</span>是训练深度学习网络的核心算法之一，梯度从输出层开始，一层层“反向”传播回输入层，更新每一层的权重（参数）。而<span style=\"color:red\">前向传播</span>：输入->经过神经网络->得到输出（预测）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4bbb7-680f-4341-ba6e-93ec61cc5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. 输入和目标（注意：需要是 float 类型）\n",
    "x = torch.tensor([[0.5, -0.2]], requires_grad=True)   # 输入特征\n",
    "y_true = torch.tensor([[1.0]])                        # 目标输出\n",
    "\n",
    "# 2. 简单的线性模型：输入(2) -> 输出(1)\n",
    "model = nn.Linear(2, 1)  # 自动初始化权重和偏置\n",
    "\n",
    "# 3. 损失函数：均方误差\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 4. 前向传播\n",
    "y_pred = model(x)\n",
    "\n",
    "# 5. 计算损失\n",
    "loss = criterion(y_pred, y_true)\n",
    "\n",
    "# 6. 反向传播\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a7264-90ef-4424-ada3-9553b5ed1161",
   "metadata": {},
   "source": [
    "* 反向传播更新参数时，梯度值可能变得非常小或非常大，就是所谓的<span style=\"color:red\">梯度消失</span>或<span style=\"color:red\">梯度爆炸</span>，梯度消失会导致深层特征并没有被学习到但参数不再更新，如前边提到的局部极小值，梯度爆炸会导致参数直接变成NaN，训练无法继续，造成梯度消失和梯度爆炸的原因有很多，比如学习率过高或过低，所以学习率这种超参数需要在实验过程中慢慢调试。\n",
    "* <span style=\"color:red\">鞍点</span>的梯度也为零，但区别于局部极小值和局部极大值，如图中红色的点在y轴方向比较高，但在x轴方向是比较低的。我们把梯度为零的点统称为<span style=\"color:red\">临界点</span>。\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/局部极小值&鞍点.png\" width=\"35%\">\n",
    "</p>   \n",
    "\n",
    "* 应对梯度消失和梯度爆炸的策略有<span style=\"color:red\">批量归一化（Batch Normalization，BN）</span>，如今几乎是神经网络的标配，网络每一层的输出如果数值分布变化太大，会让网络训练困难，BN在每一层后把输出重新“归一化”，让数值更加平稳、集中，模型更容易收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d1f30-fe9d-4962-9ede-a90d83a4760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 用于全连接层输出\n",
    "nn.BatchNorm1d(num_features)\n",
    "\n",
    "# 用于卷积层输出（特征图）\n",
    "nn.BatchNorm2d(num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34f8b7-c8c7-4284-ab65-551add4dc006",
   "metadata": {},
   "source": [
    "* 除了批归一化以外，还有<span style=\"color:red\">特征归一化（Feature Normalization,FN）</span>等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee9774-273a-47d0-a945-4cca3d195c95",
   "metadata": {},
   "source": [
    "* 深层网络很容易出现<span style=\"color:red\">过拟合</span>，最明显的表现是模型在训练集上表现非常好，但在验证集和测试集上表现很差，也就是说模型记住了训练数据，而不是学会了泛化规律。为了解决该问题，很多时候采用<span style=\"color:red\">正则化</span>的策略，通俗地讲，是给模型加上一些约束，防止它“死记硬背”，例如L1正则化和L2正则化，还有<span style=\"color:red\">Dropout</span>，其策略是训练时随机“屏蔽”一部分神经元，防止模型对某些神经元太依赖，而测试时自动关闭Dropout。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f5bed-9c28-4201-ba6b-76bb3d87aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "nn.Dropout(p=0.5)  # 每次随机丢掉50%的神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fa307-b1cb-47f4-ac74-6ab5203b4374",
   "metadata": {},
   "source": [
    "* 另外一个解决过拟合的策略是<span style=\"color:red\">数据增强</span>，例如通过对训练数据做旋转、缩放、加噪声等方式，人为扩种数据多样性，让模型学会适应更多的情况，所以可以讲训练数据集越小，网络越深，越容易产生过拟合。\n",
    "* 另外一个解决过拟合的策略是<span style=\"color:red\">早停</span>，当验证集的损失不再下降时，就提前停止训练。\n",
    "* 除了过拟合以外，还有一个严重问题，就是<span style=\"color:red\">数据泄露</span>，指的是训练过程中使用了测试集的信息，或者用了模型不该提前知道的特征，你以为模型预测很准，其实它是提前“偷看了答案”才那么准，真正面对新数据时完全不行，例如测试集的数据混入训练集，用测试集做特征选择、调参、归一化等。\n",
    "* 相反，过于<span style=\"color:red\">简单的模型</span>，会产生<span style=\"color:red\">模型偏差</span>，即模型在学习过程中的系统误差，也就是它对真实关系的理解能力差，导致预测结果总是离正确值有偏差，就比如你用一个线性模型学习一个非线性函数，无论喂多少数据，调多少次参数，模型的训练结果都不够好，因为模型本身就太简单。表现在训练误差很大，并且测试误差也很大，随着训练继续也不会好转。\n",
    "* 如果给模型的<span style=\"color:red\">限制过多</span>也会导致模型偏差。\n",
    "* 除了模型本身的复杂度以外，<span style=\"color:red\">优化做得不好</span>也容易产生模型偏差，就比如前边讲到的梯度下降，既可能找到全局最小值，也可能找到局部最小值，优化梯度下降不给力，就会容易卡在局部最小值处。常用的优化方法是自适应学习率，如<span style=\"color:red\">Adam</span>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41258744-6d27-4fa2-aaf6-b6ef41fa6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. 构造训练数据\n",
    "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
    "y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
    "\n",
    "# 2. 定义模型：简单线性回归 y = wx + b\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# 3. 损失函数：均方误差 MSE\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 4. 优化器：Adam（学习率可调）\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 5. 训练过程\n",
    "for epoch in range(200):\n",
    "    # 前向传播\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    # 清空旧梯度\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 更新参数（Adam 优化）\n",
    "    optimizer.step()\n",
    "\n",
    "    # 打印训练过程\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfe665-604e-4c16-966b-c49fd2491e47",
   "metadata": {},
   "source": [
    "* 除此以外，还有一个问题需要补充：<span style=\"color:red\">不匹配</span>。例如训练数据与测试数据分布不同，实际使用的数据来源不同，模型训练的优化目标与实际任务目标不一致，训练阶段和测试阶段数据预处理方式不一致（如归一化），训练使用了dropout，但测试没有给关掉，导致测试时预测根本不准，这可能不是因为过拟合的问题，可能就是以上这些不匹配问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45ff3d-e2c1-46e4-9d99-313750d37363",
   "metadata": {},
   "source": [
    "* 此外卷积神经网络还有一些补充概念。\n",
    "* 对于机器，图像可以描述为三维<span style=\"color:red\">张量</span>（张量可以想象成维度大于2的矩阵），一维代表图像的宽，一维代表图像的高，还有一维代表图像的<span style=\"color:red\">通道（channel）</span>的数目。\n",
    "* 卷积神经网络会设定一个区域，即<span style=\"color:red\">感受野</span>，每个神经元都只关心自己的感受野里面发生的事情，感受野是由我们自己决定。\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/感受野.png\" width=\"35%\">\n",
    "</p>   \n",
    "\n",
    "* 我们把右上角的感受野往右移一个步幅，就制造出一个新的感受野，移动的量称之为<span style=\"color:red\">步幅（stride）</span>，步幅是一个超参数，需要人为调整，一般不会设置太大。当感受野超出了图像的范围进行补零值，称之为<span style=\"color:red\">填充（padding）</span>。\n",
    "* 不同感受野的神经元可以进行<span style=\"color:red\">参数共享</span>，所谓参数共享就是两个神经元的参数（权重）完全是一样的。\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/共享参数.png\" width=\"35%\">\n",
    "</p>   \n",
    "\n",
    "* 感受野、参数共享本质都是简化，<span style=\"color:red\">全连接层</span>可以自己决定看整张图片还是一个小范围，加上感受野的概念后，只能看一个小范围，而加入参数共享后某一些神经元无论如何参数都要一模一样，这又增加了对神经元的限制，而感受野加上参数共享就是<span style=\"color:red\">卷积层</span>，用到卷积层的网络就叫卷积神经网络。卷积层会改变图像的通道数而不会改变高和宽。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857b9ff-3f0a-4b4d-9586-33300ccb6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个卷积层：输入通道 3（RGB图像），输出通道 16，卷积核大小 3x3\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138d2db-cfa5-4e9b-81b5-edc191777d1e",
   "metadata": {},
   "source": [
    "* 卷积神经网络中，<span style=\"color:red\">池化（pooling）</span>主要用于简化特征、降低过拟合的风险，常见的池化右最大池化（Max Pooling）、平均池化（Avg Pooling）和全局平局池化（Global Avg Pooling）。池化会改变图像的高和宽而不会改变通道数。\n",
    "  <p align=\"center\">\n",
    "  <img src=\"resource/最大池化.png\" width=\"35%\">\n",
    "</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a504f8-2910-4e50-8db7-8826e6fd1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 最大池化层：窗口大小 2x2，步长 2\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# 平均池化层\n",
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "通常池化层会接在卷积层之后，例如：\n",
    "nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b23d95-4872-4e58-9a51-87ca16bec137",
   "metadata": {},
   "source": [
    "* 池化和<span style=\"color:red\">下采样</span>都可以简化特征，而下采样指代更广义的尺寸缩小方法，不拘泥于池化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db948fea-3f0d-4076-a2f6-e0a74fa3659a",
   "metadata": {},
   "source": [
    "## 实战：探地雷达数据反演实验\n",
    "### 数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e798be26-7839-47bc-bd8d-689d96221172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from scipy.ndimage import zoom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class OneStageDataset(Dataset):\n",
    "    def __init__(self, bscan_folder, diel_label_folder, mode='train', num_class = 4, target_size=(200, 375)):\n",
    "        self.bscan_folder = bscan_folder\n",
    "        self.diel_label_folder = diel_label_folder\n",
    "        self.bscan_files = self.load_h5_files(bscan_folder)\n",
    "        self.diel_label_files = self.load_h5_files(diel_label_folder)\n",
    "        self.target_size = target_size\n",
    "        self.num_classes = num_class\n",
    "\n",
    "        # 检查文件数量是否一致\n",
    "        if not (len(self.bscan_files) == len(self.diel_label_files)):\n",
    "            raise ValueError(\"每个文件夹中的文件数量必须相同！\")\n",
    "\n",
    "        # 划分文件名索引\n",
    "        self.train_indices, self.val_indices, self.test_indices = self.split_dataset()\n",
    "\n",
    "        # 根据模式选择索引\n",
    "        if mode == 'train':\n",
    "            self.indices = self.train_indices\n",
    "        elif mode == 'val':\n",
    "            self.indices = self.val_indices\n",
    "        elif mode == 'test':\n",
    "            self.indices = self.test_indices\n",
    "        elif mode == \"all\":\n",
    "            self.indices = np.arange(len(self.bscan_files))\n",
    "        else:\n",
    "            raise ValueError(\"模式必须是 'train', 'val' 或 'test'\")\n",
    "\n",
    "    def load_h5_files(self, folder_path):\n",
    "        files = []\n",
    "        filenames = os.listdir(folder_path)\n",
    "        filenames.sort()\n",
    "        for file_name in filenames:\n",
    "            if file_name.endswith('.h5') or file_name.endswith('.out'):\n",
    "                files.append(file_name)\n",
    "        return files\n",
    "\n",
    "    def split_dataset(self):\n",
    "        # 记录所有文件的索引\n",
    "        all_indices = np.arange(len(self.bscan_files))\n",
    "        # 划分索引\n",
    "        # train_indices, temp_indices = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
    "        # val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "        _, temp_indices = train_test_split(all_indices, test_size=0.02, random_state=42)\n",
    "        train_indices, temp_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "        val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "        return train_indices, val_indices, test_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)  # 返回当前模式下样本数量\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 根据索引获取文件名\n",
    "        bscan_file = self.bscan_files[self.indices[idx]]\n",
    "        diel_file = self.diel_label_files[self.indices[idx]]\n",
    "\n",
    "        # 加载数据\n",
    "        bscan_data = self.load_h5_data(os.path.join(self.bscan_folder, bscan_file), 'rxs/rx1/Ez')\n",
    "        diel_data = self.load_h5_data(os.path.join(self.diel_label_folder, diel_file), 'data')\n",
    "\n",
    "        bscan_data = np.squeeze(bscan_data)\n",
    "        diel_data = np.squeeze(diel_data)\n",
    "\n",
    "        # Resize 数据\n",
    "        bscan_data = self.resize(bscan_data) # / 100000\n",
    "        diel_data = self.resize(diel_data)\n",
    "\n",
    "\n",
    "        return (\n",
    "            torch.tensor(bscan_data, dtype=torch.float32).unsqueeze(0),\n",
    "            torch.tensor(diel_data, dtype=torch.float32).unsqueeze(0),\n",
    "            bscan_file,\n",
    "        )\n",
    "\n",
    "    def load_h5_data(self, file_path, dataset_name):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = f[dataset_name][:]\n",
    "        return data\n",
    "\n",
    "    def resize(self, data):\n",
    "        # 使用zoom函数进行二维缩放\n",
    "        data_dims = data.ndim\n",
    "        \n",
    "        # 计算缩放因子\n",
    "        if data_dims == 2:\n",
    "            zoom_factor = (self.target_size[0] / data.shape[0], self.target_size[1] / data.shape[1])\n",
    "        elif data_dims == 3:\n",
    "            zoom_factor = (1, self.target_size[0] / data.shape[1], self.target_size[1] / data.shape[2])  # 保持第一个维度不变\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected B-scan dimensions: {data_dims}\")\n",
    "        \n",
    "\n",
    "        resized_data = zoom(data, zoom_factor, order=0)  # order=1 表示双线性插值\n",
    "\n",
    "        return resized_data\n",
    "\n",
    "# 示例用法\n",
    "# dataset = TwoStageDataset('path/to/bscan_folder', 'path/to/cls_label_folder', 'path/to/diel_label_folder')\n",
    "\n",
    "def test():\n",
    "    # 设置文件夹路径\n",
    "    bscan_folder = r'D:\\Test\\Z-GprMax\\DeepLearning\\dataset\\twostageinversion\\OneCircleAndRectOBJ\\bscan'\n",
    "    cls_label_folder = r'D:\\Test\\Z-GprMax\\DeepLearning\\dataset\\twostageinversion\\OneCircleAndRectOBJ\\cls_label'\n",
    "    diel_label_folder = r'D:\\Test\\Z-GprMax\\DeepLearning\\dataset\\twostageinversion\\OneCircleAndRectOBJ\\diel_label'\n",
    "    \n",
    "    # 检查文件夹是否存在\n",
    "    if not (os.path.exists(bscan_folder) and os.path.exists(cls_label_folder) and os.path.exists(diel_label_folder)):\n",
    "        raise FileNotFoundError(\"请确保所有文件夹路径都存在！\")\n",
    "\n",
    "    # 创建数据集实例\n",
    "    train_dataset = OneStageDataset(bscan_folder, cls_label_folder, diel_label_folder, mode='train')\n",
    "    val_dataset = OneStageDataset(bscan_folder, cls_label_folder, diel_label_folder, mode='val')\n",
    "    test_dataset = OneStageDataset(bscan_folder, cls_label_folder, diel_label_folder, mode='test')\n",
    "\n",
    "    # 打印数据集长度\n",
    "    print(\"Train dataset length:\", len(train_dataset))\n",
    "    print(\"Validation dataset length:\", len(val_dataset))\n",
    "    print(\"Test dataset length:\", len(test_dataset))\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    # 测试数据集\n",
    "    for bscan, cls_label, diel_label, filename in train_loader:\n",
    "        print(\"Train B-scan shape:\", bscan.shape)\n",
    "        print(\"Train Classification label shape:\", cls_label.shape)\n",
    "        print(\"Train Dielectric constant label shape:\", diel_label.shape)\n",
    "        print(\"Train File name:\", filename)\n",
    "        break  # 只打印一个批次的数据\n",
    "\n",
    "    for bscan, cls_label, diel_label, filename in val_loader:\n",
    "        print(\"Validation B-scan shape:\", bscan.shape)\n",
    "        print(\"Validation Classification label shape:\", cls_label.shape)\n",
    "        print(\"Validation Dielectric constant label shape:\", diel_label.shape)\n",
    "        print(\"Validation File name:\", filename)\n",
    "        break  # 只打印一个批次的数据\n",
    "\n",
    "    for bscan, cls_label, diel_label, filename in test_loader:\n",
    "        print(\"Test B-scan shape:\", bscan.shape)\n",
    "        print(\"Test Classification label shape:\", cls_label.shape)\n",
    "        print(\"Test Dielectric constant label shape:\", diel_label.shape)\n",
    "        print(\"Test File name:\", filename)\n",
    "        break  # 只打印一个批次的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec4192-901b-4e5f-bb6d-a61f0dc85c4c",
   "metadata": {},
   "source": [
    "## 网络模型搭建MRFUNet\n",
    "该网络来源于[DMRF-UNet: A Two-Stage Deep Learning Scheme for GPR Data Inversion Under Heterogeneous Soil Conditions](https://ieeexplore.ieee.org/document/9782091):\n",
    "\n",
    "复现其网络代码结构如下，分为两个文件：\n",
    "- net_parts.py\n",
    "- net_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573e7ff8-c1d6-4291-8b82-de7eab701686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the MRFU-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MRFBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MRFBlock, self).__init__()\n",
    "        \n",
    "        # Assuming 1/4 channels means splitting into 4 groups\n",
    "        quarter_channels = out_channels // 4\n",
    "\n",
    "        # 1x1 convolution for channel reduction\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, quarter_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "        # Parallel 3x3 convolutions (each group processes quarter_channels)\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, quarter_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, quarter_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(quarter_channels, quarter_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, quarter_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(quarter_channels, quarter_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(quarter_channels, quarter_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Final 3x3 convolution after concatenation\n",
    "        self.final_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out4 = self.conv1x1(x)\n",
    "\n",
    "        # Concatenate results from all branches\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        # Final 3x3 convolution\n",
    "        out = self.final_conv(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            MRFBlock(in_channels, out_channels),\n",
    "            MRFBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # print(x1.shape)\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        # double = nn.Conv2d(x1.shape[1], x1.shape[1] * 2, kernel_size=3, padding=1).cuda()\n",
    "        # x = double(x1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f49bb4c-af99-4359-94e8-5b24a16be02d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrf_unet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_parts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMRFUNet\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      9\u001b[0m     _name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMRFUNet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'net'"
     ]
    }
   ],
   "source": [
    "#|output\n",
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from net.mrf_unet.unet_parts import *\n",
    "\n",
    "\n",
    "class MRFUNet(nn.Module):\n",
    "    _name = \"MRFUNet\"\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(MRFUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "\n",
    "        x2 = self.down1(x1)\n",
    "\n",
    "        x3 = self.down2(x2)\n",
    "\n",
    "        x4 = self.down3(x3)\n",
    "  \n",
    "        x5 = self.down4(x4)\n",
    "  \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        # logits = torch.sigmoid(logits)\n",
    "        return logits\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = MRFUNet(2,1)\n",
    "    data = torch.rand((2, 2, 200, 375))\n",
    "\n",
    "    y = model(data)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5bf80-be33-4cfd-9979-92243c213d0b",
   "metadata": {},
   "source": [
    "### 完整训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c8d474-39b8-4047-b49e-a62ec0d22d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dataset_onestage1' from 'dataset' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m     17\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_onestage1\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SegmentNet\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet \u001b[38;5;28;01mas\u001b[39;00m NET\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dataset_onestage1' from 'dataset' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from pytorch_msssim import ssim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "import sys\n",
    "import matplotlib.colors as mcolors\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from dataset import dataset_onestage1\n",
    "from net.segmentnet import SegmentNet\n",
    "from net.unet.unet_model import UNet as NET\n",
    "# from net.ManyUNet import AttU_Net as NET\n",
    "from net.mrf_unet.unet_model import MRFUNet as NET\n",
    "# from net.unet_with_mlp.mlp_net import Mlp_Net as NET\n",
    "# from net.firstnet import FirstNet\n",
    "# from net.ManyUNet import AttU_Net as NET\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # 用黑体\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "# 配置信息函数\n",
    "def get_config():\n",
    "    config = {\n",
    "        'bscan_folder': r'\\\\lei_nas\\home\\dataset\\process data\\twostageinversion\\TwoObj\\bscan',\n",
    "        'diel_label_folder': r'\\\\lei_nas\\home\\dataset\\process data\\twostageinversion\\TwoObj\\bk6_diel',\n",
    "        'model_name': NET._name,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.0001,\n",
    "        'num_epochs': 2,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'model_save_path': 'best_model.pth'  # 保存模型的路径\n",
    "    }\n",
    "    return config\n",
    "\n",
    "# 训练函数\n",
    "def train(model, train_loader, criterion_diel, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for bscan, diel_label, _ in tqdm(train_loader, desc=\"Training\", unit=\"batch\"):\n",
    "        bscan, diel_label = bscan.to(device), diel_label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # classification_output, dielectric_constant_output = model(bscan)\n",
    "        # classification_output = model(bscan)\n",
    "        dielectric_constant_output = model(bscan)\n",
    "        # loss_cls = criterion_cls(classification_output, cls_label)\n",
    "        loss_diel = criterion_diel(dielectric_constant_output, diel_label)\n",
    "        # loss = loss_cls + loss_diel  # 可以根据需要调整权重\n",
    "        loss = loss_diel\n",
    "        # loss = loss_cls\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# 验证函数\n",
    "def validate(model, val_loader, criterion_diel, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for bscan, diel_label, _ in val_loader:\n",
    "            bscan, diel_label = bscan.to(device), diel_label.to(device)\n",
    "\n",
    "            # classification_output, dielectric_constant_output = model(bscan)\n",
    "            # classification_output = model(bscan)\n",
    "            dielectric_constant_output = model(bscan)\n",
    "            # loss_cls = criterion_cls(classification_output, cls_label)\n",
    "            loss_diel = criterion_diel(dielectric_constant_output, diel_label)\n",
    "\n",
    "            # loss = loss_cls + loss_diel\n",
    "            loss = loss_diel\n",
    "            # loss = loss_cls\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(val_loader)\n",
    "\n",
    "# 测试函数\n",
    "def test(model, test_loader, device):\n",
    "    from utils import psnr, normalize_tensor_to_0_255, calculate_smape_torch\n",
    "    model.eval()\n",
    "    results = []\n",
    "    mse_total = 0\n",
    "    mae_total = 0\n",
    "    ssim_total = 0\n",
    "    mape_total = 0\n",
    "    psnr_total = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for bscan,  diel_label, filename in tqdm(test_loader, desc=\"Testing\"):\n",
    "            bscan, diel_label = bscan.to(device), diel_label.to(device)\n",
    "            # classification_output, dielectric_constant_output = model(bscan)\n",
    "            # classification_output = model(bscan)\n",
    "            dielectric_constant_output = model(bscan)\n",
    "\n",
    "            results.append((filename, dielectric_constant_output.cpu().numpy(), diel_label.cpu().numpy()))\n",
    "            dc_mse = F.mse_loss(dielectric_constant_output, diel_label, reduction='mean')\n",
    "            mse_total += dc_mse.item() \n",
    "            dc_mae = F.l1_loss(dielectric_constant_output, diel_label, reduction='mean')\n",
    "            mae_total += dc_mae.item()\n",
    "            dc_mape = calculate_smape_torch(dielectric_constant_output, diel_label)\n",
    "            mape_total += dc_mape.item()\n",
    "\n",
    "\n",
    "            dielectric_constant_output = normalize_tensor_to_0_255(dielectric_constant_output, 1, 100)\n",
    "            diel_label = normalize_tensor_to_0_255(diel_label, 1, 100)\n",
    "\n",
    "            dc_ssim = ssim(dielectric_constant_output, diel_label, 255, size_average=True)\n",
    "            ssim_total += dc_ssim.item() \n",
    "\n",
    "            psnr_total += psnr(diel_label, dielectric_constant_output).item() \n",
    "            num_samples += 1\n",
    "    avg_mse_total = mse_total / num_samples\n",
    "    avg_mae_total = mae_total / num_samples\n",
    "    avg_ssim_total = ssim_total / num_samples\n",
    "    avg_mape_total = mape_total / num_samples\n",
    "    avg_psnr_total = psnr_total / num_samples\n",
    "\n",
    "    metrics_variables = ['avg_mse_total', 'avg_mae_total', 'avg_ssim_total', 'avg_mape_total', 'avg_psnr_total', ]\n",
    "    metrics = {var : eval(var) for var in metrics_variables}\n",
    "\n",
    "    return results, metrics\n",
    "\n",
    "def test_use_pth():\n",
    "    def test_other_data(model, pth_path, test_loader, results_folder=\"results\", device = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        model.load_state_dict(torch.load(pth_path, weights_only=False))\n",
    "        test_results, metrics_dict = test(model, test_loader, device)\n",
    "        filenames, diel_outputs, diel_labels = zip(*test_results)\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        folder = f'test_onestage_{timestamp}_{model._name}_3obj'\n",
    "        os.makedirs(os.path.join(results_folder, folder), exist_ok=False)\n",
    "\n",
    "        with open(os.path.join(results_folder, folder, 'matrix.txt'), 'w') as file:\n",
    "            # 写入内容\n",
    "            contents = []\n",
    "            for k, v in metrics_dict.items():\n",
    "                contents.append(f\"{k}:{v}\\n\")\n",
    "            content = ''.join(contents)\n",
    "            file.write(content)\n",
    "\n",
    "       \n",
    "        # 保存结果\n",
    "        save_results(filenames, diel_outputs, diel_labels, os.path.join(results_folder, folder)) \n",
    "        # save_results(filenames, cls_outputs, small_outputs, great_outputs, cls_labels, small_labels, great_labels, os.path.join(results_folder, folder)) \n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = NET(1, 1).to(device)\n",
    "    # dataset = dateset_twostage2.TwoStageDataset(r'D:\\Test\\Z-GprMax\\test\\inversion2step\\two_obj\\pec_air\\out',\n",
    "    #                                             r'D:\\Test\\Z-GprMax\\test\\inversion2step\\two_obj\\pec_air\\cls_label',\n",
    "    #                                             r'D:\\Test\\Z-GprMax\\test\\inversion2step\\two_obj\\pec_air\\smaller_label',\n",
    "    #                                             r'D:\\Test\\Z-GprMax\\test\\inversion2step\\two_obj\\pec_air\\greater_label',\n",
    "    #                                             mode='all')\n",
    "    dataset = dataset_onestage1.OneStageDataset(r'D:\\Test\\Z-GprMax\\datas\\ThreeobjTest\\process\\bscan',\n",
    "                                                r'D:\\Test\\Z-GprMax\\datas\\ThreeobjTest\\process\\bk6_diel',\n",
    "                                                mode='all')\n",
    "    config = get_config()\n",
    "    train_loader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "    pth_path = r'D:\\两阶段电磁反演\\results\\normal\\20250114_041030_MRFUNet\\best_model.pth'\n",
    "\n",
    "\n",
    "    test_other_data(model, pth_path, train_loader)\n",
    "\n",
    "# 绘制损失曲线\n",
    "def plot_loss(train_losses, val_losses, save_dir):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 保存结果函数\n",
    "def save_results(filenames, diel_outputs, diel_labels, save_folder):\n",
    "    diel_res_folder = os.path.join(save_folder, \"test_output\", \"diel_res\")\n",
    "    os.makedirs(diel_res_folder, exist_ok=True)\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    # 定义颜色和区间\n",
    "    # colors = [\n",
    "    #             (0, \"blue\"),  # 区间起点和颜色\n",
    "    #             (0.005, \"white\"),\n",
    "    #             (0.06, \"pink\"),\n",
    "    #             (0.18, \"cyan\"),  # 1到20的细致渐变\n",
    "    #             (0.36, \"green\"),  # 20到40的细致渐变\n",
    "    #             (0.64, \"yellow\"),  # 40到70的细致渐变\n",
    "    #             (0.82, \"orange\"),  # 70到90的细致渐变\n",
    "    #             (0.91, \"red\"),  # 90到100的细致渐变\n",
    "    #             (1, \"darkred\")  # 100到110的颜色\n",
    "    #         ]\n",
    "\n",
    "    # # 创建自定义颜色映射\n",
    "    # custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "    bounds = [0, 0.5, 2.5, 4.5, 7.5, 10, 15, 25, 50, 85, 110]\n",
    "\n",
    "    colors = [\n",
    "        'darkblue',      # 深蓝\n",
    "        'mediumblue',    # 中蓝\n",
    "        'royalblue',     # 皇家蓝\n",
    "        'dodgerblue',    # 道奇蓝\n",
    "        'deepskyblue',   # 深天蓝\n",
    "        'mediumseagreen', # 中海绿\n",
    "        'hotpink',       # 亮粉\n",
    "        'red',           # 红色\n",
    "        'orange',        # 橙色\n",
    "        'yellow'         # 黄色\n",
    "    ]\n",
    "    n_bins = 100  # 颜色分布的细分数量\n",
    "    cmap_name = 'custom_cmap'\n",
    "    # 创建自定义颜色映射\n",
    "    cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
    "\n",
    "    # 创建 BoundaryNorm 对象，确保每个区间的长度在 colorbar 中相等\n",
    "    norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=n_bins)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for filename, diel_output, diel_label in tqdm(zip(filenames, diel_outputs, diel_labels), desc=\"GenerateImg\"):\n",
    "            # diel_output = diel_output.squeeze()\n",
    "            diel_label = diel_label.squeeze()\n",
    "            for f, do, dl in zip(filename, diel_output, diel_label):\n",
    "                f = f.replace(\".out\", \".jpg\")\n",
    "                do = do.squeeze()\n",
    "                dl = dl.squeeze()\n",
    "                vmin, vmax = 0, dl.max()\n",
    "                # 绘制介电常数结果与标签对比\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "                im = axs[0].imshow(do, cmap=cmap, norm=norm, interpolation=\"none\", extent=[0, 1.5, 0.8, 0])\n",
    "                axs[0].set_title('Predicted Dielectric Constant')\n",
    "                axs[0].set_ylabel(\"Depth/m\")\n",
    "                axs[0].set_xlabel(\"Detection distance/m\")\n",
    "                # plt.colorbar(axs[0].imshow(do, cmap=custom_cmap, aspect='equal'), ax=axs[0])\n",
    "                \n",
    "                im = axs[1].imshow(dl, cmap=cmap, norm=norm, interpolation=\"none\", extent=[0, 1.5, 0.8, 0])\n",
    "                axs[1].set_title('True Dielectric Constant')\n",
    "                axs[1].set_ylabel(\"Depth/m\")\n",
    "                axs[1].set_xlabel(\"Detection distance/m\")\n",
    "                cbar = fig.colorbar(im, ticks=bounds, ax=axs)\n",
    "                cbar.set_ticks(bounds)  # 设置 colorbar 的刻度为指定的范围\n",
    "                cbar.set_ticklabels([0, 1, 3, 5, 8, 10, 15, 25, 50, 85, 110])  # 设置标签\n",
    "                \n",
    "                plt.savefig(os.path.join(diel_res_folder, f'diel_{f}'))\n",
    "                plt.close(fig)\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    config = get_config()\n",
    "    OneStageDataset = dataset_onestage1.OneStageDataset\n",
    "    \n",
    "    # 创建结果保存文件夹\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_folder = f'results/{timestamp}_{config[\"model_name\"]}'\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    # 创建数据集和数据加载器\n",
    "    train_dataset = OneStageDataset(config['bscan_folder'], config['diel_label_folder'], mode='train')\n",
    "    val_dataset = OneStageDataset(config['bscan_folder'], config['diel_label_folder'], mode='val')\n",
    "    test_dataset = OneStageDataset(config['bscan_folder'], config['diel_label_folder'], mode='test')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=8, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # 初始化模型、损失函数和优化器\n",
    "    device = config['device']\n",
    "    # model = FirstNet().to(device)\n",
    "    model = NET(1, 1).to(device)\n",
    "    criterion_diel = nn.MSELoss()  # 第二阶段使用均方误差损失\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')  # 初始化最佳验证损失\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        train_loss = train(model, train_loader, criterion_diel, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion_diel, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{config[\"num_epochs\"]}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # 保存验证损失最低的模型权重\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(results_folder, config['model_save_path']))\n",
    "            print(f'Saved best model with validation loss: {best_val_loss:.4f}')\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plot_loss(train_losses, val_losses, results_folder)\n",
    "\n",
    "    # 测试并保存结果\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(torch.load(os.path.join(results_folder, config['model_save_path']), weights_only=False))\n",
    "    test_results, metrics_dict = test(model, test_loader, device)\n",
    "    filenames, diel_outputs, diel_labels = zip(*test_results)\n",
    "    with open(os.path.join(results_folder, 'matrix.txt'), 'w') as file:\n",
    "        # 写入内容\n",
    "        contents = []\n",
    "        for k, v in metrics_dict.items():\n",
    "            contents.append(f\"{k}:{v}\\n\")\n",
    "        content = ''.join(contents)\n",
    "        file.write(content)\n",
    "\n",
    "    # 保存结果\n",
    "    save_results(filenames, diel_outputs, diel_labels, results_folder) \n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
